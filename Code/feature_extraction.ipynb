{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature_extraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN1BFYsF9pD2btNRUcKSOoU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinayakShenoy/DL4CV/blob/master/Code/feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuRsfIACXrQX",
        "colab_type": "text"
      },
      "source": [
        "# Feature extraction process\n",
        "- Python script that can be used to extract features from an arbitrary image dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmyidUh-YPTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install imutils\n",
        "!pip install import_ipynb\n",
        "!pip install progressbar\n",
        "!git clone http://github.com/vinayakShenoy/DL4CV\n",
        "%cd DL4CV/Code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rxPJhxTnnVH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "228a23cf-bd9e-492f-9b24-76b7d0e5ffc0"
      },
      "source": [
        "!kaggle datasets download -d ashishsaxena2209/animal-image-datasetdog-cat-and-panda\n",
        "!kaggle datasets download -d athota1/caltech101"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading animal-image-datasetdog-cat-and-panda.zip to /content/DL4CV/Code\n",
            " 98% 367M/376M [00:04<00:00, 89.4MB/s]\n",
            "100% 376M/376M [00:04<00:00, 85.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj_zK2dhoQBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip animal*\n",
        "!unzip calte*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkjais4For7Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "30377a28-f0fe-4548-c0f8-87f9cdcc8490"
      },
      "source": [
        "!ls animals/animals|wc -l \n",
        "!rm -rf 101_Ob*/BACK*\n",
        "!ls 101_ObjectCategories|wc -l"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KBzbTBeXzb7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f517c69c-a4a8-4ade-88f5-2c9dc730a313"
      },
      "source": [
        "from tensorflow.keras.applications import VGG16, imagenet_utils\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import imutils\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import progressbar\n",
        "import import_ipynb\n",
        "from pyimage.io.hdf5py import HDF5DatasetWriter\n",
        "from imutils import paths"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "importing Jupyter notebook from /content/DL4CV/Code/pyimage/io/hdf5py.ipynb\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tB0BLvnZQQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_features(dataset, output, batch_size=32, buffer_size=1000):\n",
        "  args = {\n",
        "      \"dataset\":dataset,\n",
        "      \"output\": output,\n",
        "      \"batch-size\": batch_size,\n",
        "      \"buffer-size\": buffer_size\n",
        "  }\n",
        "\n",
        "  bs = args[\"batch-size\"]\n",
        "\n",
        "  # grab the list of images that we'll be describing then randomly\n",
        "  # shuffle them to allow for easy training and testing splits via\n",
        "  # array slicing during training time\n",
        "  print(\"INFO loading images\")\n",
        "  imagePaths = list(paths.list_images(args[\"dataset\"]))\n",
        "  random.shuffle(imagePaths)\n",
        "\n",
        "  # extract the class labels from the image paths then encode the\n",
        "  # labels\n",
        "  labels = [p.split(os.path.sep)[-2] for p in imagePaths]\n",
        "  le = LabelEncoder()\n",
        "  labels = le.fit_transform(labels)\n",
        "\n",
        "  # load vgg16 network\n",
        "  print(\"INFO loading network\")\n",
        "  model = VGG16(weights=\"imagenet\", include_top=False)\n",
        "\n",
        "  # init hdf5, and store class label names in dataset\n",
        "  dataset = HDF5DatasetWriter((len(imagePaths), 512*7*7),\n",
        "                              args[\"output\"], dataKey=\"features\", bufSize=args[\"buffer-size\"])\n",
        "  dataset.storeClassLabels(le.classes_)\n",
        "\n",
        "  widgets = [\"extracting features: \", progressbar.Percentage(), \" \", progressbar.Bar(), \" \", progressbar.ETA()]\n",
        "  pbar = progressbar.ProgressBar(maxval=len(imagePaths), widgets=widgets).start()\n",
        "\n",
        "  for i in np.arange(0, len(imagePaths), bs):\n",
        "    # extract the batch of images and labels, then init the list of actual images that\n",
        "    # will be passed through the network for feature extraction\n",
        "    batchPaths = imagePaths[i:i+bs]\n",
        "    batchLabels = labels[i:i+bs]\n",
        "    batchImages = []\n",
        "\n",
        "    for (j, imagePath) in enumerate(batchPaths):\n",
        "      # load the input image and resize to vgg16 input size\n",
        "      image = load_img(imagePath, target_size=(224,224))\n",
        "      image = img_to_array(image)\n",
        "\n",
        "      # preprocess image by expanding dimensions and \n",
        "      # subtracting mean RGB from dataset\n",
        "      image = np.expand_dims(image, axis=0)\n",
        "      image = imagenet_utils.preprocess_input(image)\n",
        "\n",
        "      # add image to batch\n",
        "      batchImages.append(image)\n",
        "    \n",
        "    # pass the images through the network and use the outputs as our actual features\n",
        "    batchImages = np.vstack(batchImages)\n",
        "    features = model.predict(batchImages, batch_size=bs)\n",
        "\n",
        "    # reshape the features so that each image is represented by a flattened \n",
        "    # feature vector of the MaxPooling2D outputs\n",
        "    features = features.reshape((features.shape[0], 512*7*7))\n",
        "\n",
        "    # add features and labels to HDF5 dataset\n",
        "    dataset.add(features, batchLabels)\n",
        "    pbar.update(i)\n",
        "\n",
        "  dataset.close()\n",
        "  pbar.finish()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwxT18pQdk04",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "877c05c5-96d6-4218-ee68-131f0e4332f1"
      },
      "source": [
        "# Extracting features from animals dataset\n",
        "extract_features(\"animals/animals\", \"features_animals.hdf5\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO loading images\n",
            "INFO loading network\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0qrOTHAejxE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "365ed9d1-1224-4362-be12-473a378f8086"
      },
      "source": [
        "# Extracting features from caltech-101 dataset\n",
        "extract_features(\"101_ObjectCategories\", \"features_caltech101.hdf5\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO loading images\n",
            "INFO loading network\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU5-GrGJtmqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "import pickle\n",
        "import h5py"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNH3bvA5sOG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# db: path to hdf5 dataset containing extracted features\n",
        "# model: path to our output logistic regression classifier\n",
        "# jobs: specify number of concurrent jobs when running a grid search to tune hyperparamaters.\n",
        "def train_model(db, model=None, jobs=1):\n",
        "  db = h5py.File(db, \"r\")\n",
        "\n",
        "  #to initializer train-test split\n",
        "  i = int(db[\"labels\"].shape[0]*0.75)\n",
        "\n",
        "  # define set of parameters that we want to tune then start a grid search where\n",
        "  # we evaluate our model for each value of C\n",
        "  print(\"INFO tuning hyperparameters\")\n",
        "  params = {\"C\":[0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]}\n",
        "  model = GridSearchCV(LogisticRegression(solver=\"lbfgs\", \n",
        "                                          multi_class=\"auto\"), params, cv=3, n_jobs=jobs)\n",
        "  model.fit(db[\"features\"][:i], db[\"labels\"][:i])\n",
        "  print(\"INFO best hyperparameters: {}\".format(model.best_params_))\n",
        "\n",
        "  # evaluate model\n",
        "  preds = model.predict(db[\"features\"][i:])\n",
        "  print(classification_report(db[\"labels\"][i:], preds, target_names=db[\"label_names\"]))\n",
        "\n",
        "  # serializer the model to disk\n",
        "  f = open(args[\"model\"])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkCE70mFvbVo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "6352c1fe-0df9-40c4-985b-14f5811eb383"
      },
      "source": [
        "train_model(\"features_animals.hdf5\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO tuning hyperparameters\n",
            "INFO best hyperparameters: {'C': 10000.0}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        cats       0.96      1.00      0.98       244\n",
            "        dogs       1.00      0.96      0.98       267\n",
            "       panda       1.00      1.00      1.00       239\n",
            "\n",
            "    accuracy                           0.99       750\n",
            "   macro avg       0.99      0.99      0.99       750\n",
            "weighted avg       0.99      0.99      0.99       750\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG0MroE7veRa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "adeab78e-c563-4856-d91a-19cc3274cf70"
      },
      "source": [
        "train_model(\"features_caltech101.hdf5\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO tuning hyperparameters\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO best hyperparameters: {'C': 1.0}\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "          Faces       0.98      1.00      0.99       111\n",
            "     Faces_easy       1.00      0.98      0.99       120\n",
            "       Leopards       0.96      1.00      0.98        50\n",
            "     Motorbikes       1.00      0.99      1.00       200\n",
            "      accordion       1.00      1.00      1.00        18\n",
            "      airplanes       1.00      0.99      1.00       197\n",
            "         anchor       1.00      0.90      0.95        10\n",
            "            ant       0.83      0.71      0.77         7\n",
            "         barrel       1.00      1.00      1.00        14\n",
            "           bass       0.78      0.82      0.80        17\n",
            "         beaver       0.80      0.73      0.76        11\n",
            "      binocular       1.00      0.75      0.86         8\n",
            "         bonsai       0.94      0.92      0.93        37\n",
            "          brain       0.96      0.92      0.94        26\n",
            "   brontosaurus       0.92      0.86      0.89        14\n",
            "         buddha       0.95      1.00      0.97        18\n",
            "      butterfly       1.00      0.89      0.94        27\n",
            "         camera       1.00      1.00      1.00        13\n",
            "         cannon       1.00      1.00      1.00        12\n",
            "       car_side       1.00      1.00      1.00        33\n",
            "    ceiling_fan       0.90      0.90      0.90        10\n",
            "      cellphone       0.93      1.00      0.97        14\n",
            "          chair       1.00      1.00      1.00        15\n",
            "     chandelier       0.91      1.00      0.95        30\n",
            "    cougar_body       0.86      1.00      0.92         6\n",
            "    cougar_face       0.93      0.87      0.90        15\n",
            "           crab       0.82      0.88      0.85        16\n",
            "       crayfish       0.93      0.76      0.84        17\n",
            "      crocodile       0.59      0.91      0.71        11\n",
            " crocodile_head       0.92      0.85      0.88        13\n",
            "            cup       1.00      0.94      0.97        17\n",
            "      dalmatian       1.00      1.00      1.00        18\n",
            "    dollar_bill       0.92      1.00      0.96        11\n",
            "        dolphin       0.94      0.94      0.94        17\n",
            "      dragonfly       0.92      1.00      0.96        12\n",
            "electric_guitar       0.94      1.00      0.97        16\n",
            "       elephant       0.95      0.90      0.93        21\n",
            "            emu       1.00      0.88      0.93        16\n",
            "      euphonium       0.94      1.00      0.97        16\n",
            "           ewer       1.00      0.96      0.98        23\n",
            "          ferry       1.00      1.00      1.00        19\n",
            "       flamingo       0.86      1.00      0.92        18\n",
            "  flamingo_head       1.00      1.00      1.00        11\n",
            "       garfield       1.00      0.90      0.95        10\n",
            "        gerenuk       1.00      1.00      1.00         7\n",
            "     gramophone       0.92      1.00      0.96        11\n",
            "    grand_piano       1.00      1.00      1.00        30\n",
            "      hawksbill       0.96      1.00      0.98        22\n",
            "      headphone       0.88      0.88      0.88        16\n",
            "       hedgehog       0.82      1.00      0.90         9\n",
            "     helicopter       0.95      1.00      0.98        21\n",
            "           ibis       0.85      0.85      0.85        13\n",
            "   inline_skate       1.00      1.00      1.00        11\n",
            "    joshua_tree       0.81      0.85      0.83        20\n",
            "       kangaroo       1.00      1.00      1.00        20\n",
            "          ketch       0.91      0.97      0.94        30\n",
            "           lamp       1.00      0.89      0.94        18\n",
            "         laptop       1.00      1.00      1.00        20\n",
            "          llama       1.00      1.00      1.00        13\n",
            "        lobster       0.71      0.91      0.80        11\n",
            "          lotus       0.62      0.57      0.59        14\n",
            "       mandolin       1.00      1.00      1.00        13\n",
            "         mayfly       0.88      1.00      0.93         7\n",
            "        menorah       0.95      0.95      0.95        20\n",
            "      metronome       0.89      1.00      0.94         8\n",
            "        minaret       1.00      1.00      1.00        15\n",
            "       nautilus       1.00      1.00      1.00        12\n",
            "        octopus       1.00      0.82      0.90        11\n",
            "          okapi       1.00      1.00      1.00         5\n",
            "         pagoda       1.00      1.00      1.00         8\n",
            "          panda       1.00      0.89      0.94         9\n",
            "         pigeon       1.00      0.91      0.95        11\n",
            "          pizza       0.92      1.00      0.96        11\n",
            "       platypus       0.75      0.50      0.60         6\n",
            "        pyramid       1.00      0.92      0.96        12\n",
            "       revolver       1.00      0.94      0.97        17\n",
            "          rhino       0.93      1.00      0.96        13\n",
            "        rooster       1.00      0.88      0.93         8\n",
            "      saxophone       1.00      0.94      0.97        16\n",
            "       schooner       0.93      0.78      0.85        18\n",
            "       scissors       0.88      1.00      0.93         7\n",
            "       scorpion       0.91      0.95      0.93        21\n",
            "      sea_horse       0.89      0.89      0.89         9\n",
            "         snoopy       1.00      1.00      1.00        10\n",
            "    soccer_ball       1.00      1.00      1.00        26\n",
            "        stapler       1.00      1.00      1.00        11\n",
            "       starfish       0.84      1.00      0.91        16\n",
            "    stegosaurus       0.92      0.79      0.85        14\n",
            "      stop_sign       0.94      1.00      0.97        17\n",
            "     strawberry       1.00      1.00      1.00         9\n",
            "      sunflower       0.96      0.96      0.96        28\n",
            "           tick       1.00      0.86      0.92        14\n",
            "      trilobite       1.00      1.00      1.00        21\n",
            "       umbrella       0.90      1.00      0.95        18\n",
            "          watch       1.00      0.97      0.98        62\n",
            "    water_lilly       0.60      0.75      0.67        12\n",
            "     wheelchair       0.90      0.90      0.90        10\n",
            "       wild_cat       1.00      0.71      0.83         7\n",
            "  windsor_chair       1.00      1.00      1.00        14\n",
            "         wrench       0.89      0.89      0.89         9\n",
            "       yin_yang       1.00      0.93      0.96        14\n",
            "\n",
            "       accuracy                           0.96      2170\n",
            "      macro avg       0.94      0.93      0.93      2170\n",
            "   weighted avg       0.96      0.96      0.96      2170\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}