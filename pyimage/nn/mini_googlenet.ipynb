{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing MiniGoogleNet\n",
    "- We use tensorflow.keras.layers.Model instead of Sequential because Model will allow us to create a network graph with splits and forks like in Inception module.\n",
    "- We supply the input layer in parenthesis at the end of the function call, which is called a Functional API,like\n",
    "$$output = Layer(parameters)(input)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniGoogleNet:\n",
    "  \n",
    "  # x: input layer to function\n",
    "  # K: number of filters our CONV layer is going to learn\n",
    "  # (kX, kY): size of each K filters that will be learned\n",
    "  # stride: stride of CONV layer\n",
    "  # chanDim: The channel dimension, either \"channels last\" or \"channels first\"\n",
    "  # padding: type of padding to CONV layer\n",
    "  @staticmethod\n",
    "  def conv_module(x, K, kX, kY, stride, chanDim, padding=\"same\"):\n",
    "    # define a CONV->BN->RELU pattern\n",
    "    x = layers.Conv2D(K, (kX, kY), strides=stride, padding=padding)(x)\n",
    "    x = layers.BatchNormalization(axis=chanDim)(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    \n",
    "    return x\n",
    "  \n",
    "  # x: input layer to the function\n",
    "  # numK1x1: number of 1x1 CONV filters\n",
    "  # numK3x3: number of 3x3 CONV filters\n",
    "  # chanDim: channel along which to concatenate\n",
    "  @staticmethod\n",
    "  def inception_module(x, numK1x1, numK3x3, chanDim):\n",
    "    # define two CONV modules, then concatenate across the channel dimension\n",
    "    conv_1x1 = MiniGoogleNet.conv_module(x, numK1x1, 1, 1, (1,1), chanDim)\n",
    "    conv_3x3 = MiniGoogleNet.conv_module(x, numK3x3, 3, 3, (1,1), chanDim)\n",
    "    x = layers.concatenate([conv_1x1, conv_3x3], axis=chanDim)\n",
    "    \n",
    "    return x\n",
    "  \n",
    "  \n",
    "  @staticmethod\n",
    "  def downsample_module(x, K, chanDim):\n",
    "    # define the CONV module and POOl then concatenate across\n",
    "    # channel dimension\n",
    "    conv_3x3 = MiniGoogleNet.conv_module(x, K, 3, 3, (2,2), chanDim, padding=\"valid\")\n",
    "    pool = layers.MaxPooling2D((3,3), strides=(2,2))(x)\n",
    "    x = layers.concatenate([conv_3x3, pool], axis=chanDim)\n",
    "    return x\n",
    "  \n",
    "  @staticmethod\n",
    "  def build(width, height, depth, classes):\n",
    "    # init the input shape to be channels first and channels dimensions itelse\n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "    \n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "      inputShape = (depth, height, width)\n",
    "      chanDim = 1\n",
    "      \n",
    "    # define model input and first CONV module\n",
    "    inputs = layers.Input(shape=inputShape)\n",
    "    x = MiniGoogleNet.conv_module(inputs, 96, 3, 3, (1,1), chanDim)\n",
    "    \n",
    "    # two Inception modules followed by a downsample\n",
    "    x = MiniGoogleNet.inception_module(x, 32, 32, chanDim)\n",
    "    x = MiniGoogleNet.inception_module(x, 32, 48, chanDim)\n",
    "    x = MiniGoogleNet.downsample_module(x, 80, chanDim)\n",
    "    \n",
    "    # stack four inception modules followed by a downsample\n",
    "    x = MiniGoogleNet.inception_module(x, 112, 48, chanDim)\n",
    "    x = MiniGoogleNet.inception_module(x, 96, 64, chanDim)\n",
    "    x = MiniGoogleNet.inception_module(x, 80, 80, chanDim)\n",
    "    x = MiniGoogleNet.inception_module(x, 48, 96, chanDim)\n",
    "    x = MiniGoogleNet.downsample_module(x, 96, chanDim)\n",
    "    \n",
    "    # Two Inception modules followed by global POOL and dropout\n",
    "    # Applying an average pooling of 7×7 reduces the volume size\n",
    "    #     to 1 × 1 × 336 and thereby alleviates the need to apply many\n",
    "    #     dense fully-connected layers – instead, we simply average over\n",
    "    #     the spatial outputs of the convolution\n",
    "    x = MiniGoogleNet.inception_module(x, 176, 160, chanDim)\n",
    "    x = MiniGoogleNet.inception_module(x, 176, 160, chanDim)\n",
    "    x = layers.AveragePooling2D((7,7))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(classes)(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    \n",
    "    # create model\n",
    "    model = layers.Model(inputs, x, name=\"googlenet\")\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
