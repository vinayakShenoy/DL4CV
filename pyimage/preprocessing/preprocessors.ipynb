{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/vinayakShenoy/DL4CV/blob/master/Code/preprocessing/preprocessors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7LBDRTc__aQm"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import imutils\n",
    "from sklearn.feature_extraction.image import extract_patches_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pb9J7S7-_d41"
   },
   "outputs": [],
   "source": [
    "class SimplePreprocessor:\n",
    "    def __init__(self, width, height, inter=cv2.INTER_AREA):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.inter = inter\n",
    "        \n",
    "    def preprocess(self, image):\n",
    "        return cv2.resize(image, (self.width, self.height), \n",
    "                         interpolation=self.inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FqttCaWb_hXt"
   },
   "outputs": [],
   "source": [
    "class SimpleDatasetLoader:\n",
    "    def __init__(self, preprocessors=None):\n",
    "        self.preprocessors = preprocessors\n",
    "        if self.preprocessors is None:\n",
    "            self.preprocessors = []\n",
    "    \n",
    "    def load(self, imagePaths, verbose=-1):\n",
    "        data = []\n",
    "        labels = []\n",
    "        for (i, imagePath) in enumerate(imagePaths):\n",
    "            image = cv2.imread(imagePath)\n",
    "            label = imagePath.split(os.path.sep)[-2]\n",
    "            if self.preprocessors is not None:\n",
    "                for p in self.preprocessors:\n",
    "                    image = p.preprocess(image)\n",
    "            data.append(image)\n",
    "            labels.append(label)\n",
    "            if verbose>0 and i>0 and (i+1)%verbose==0:\n",
    "                print(\"[INFO] processed {}/{}\".format(i+1, len(imagePaths)))\n",
    "        return (np.array(data), np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S4qp1n5G_j-a"
   },
   "outputs": [],
   "source": [
    "class ImageToArrayPreprocessor:\n",
    "    def __init__(self, dataFormat=None):\n",
    "        self.dataFormat = dataFormat\n",
    "        \n",
    "    def preprocess(self, image):\n",
    "        return img_to_array(image, data_format=self.dataFormat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P7S7QotgAhNl"
   },
   "outputs": [],
   "source": [
    "class AspectAwarePreprocessor:\n",
    "    def __init__(self, width, height, inter=cv2.INTER_AREA):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.inter = inter\n",
    "  \n",
    "    def preprocess(self, image):\n",
    "        (h, w) = image.shape[:2]\n",
    "        dW = 0\n",
    "        dH = 0\n",
    "        if w<h:\n",
    "            image = imutils.resize(image, width=self.width, inter=self.inter)\n",
    "              dH = int((image.shape[0] - self.height)/2.0)\n",
    "        else:\n",
    "            image = imutils.resize(image, height=self.height, inter=self.inter)\n",
    "            dW = int((image.shape[1] - self.width)/2.0)\n",
    "\n",
    "        (h,w) = image.shape[:2]\n",
    "        image = image[dH:h-dH, dW:w-dW]\n",
    "        return cv2.resize(image, (self.width, self.height), interpolation=self.inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A mean subtraction pre-processor designed to subtract the \n",
    "# mean RGB intensities across a dataset from a input image.\n",
    "class MeanPreprocessor:\n",
    "    def __init__(self, rMean, gMean, bMean):\n",
    "        self.rMean = rMean\n",
    "        self.gMean = gMean\n",
    "        self.bMean = bMean\n",
    "    \n",
    "    def preprocess(self, image):\n",
    "        (B,G,R) = cv2.split(image.astype(\"float32\"))\n",
    "        \n",
    "        R -= self.rMean\n",
    "        G -= self.gMean\n",
    "        B -= self.bMean\n",
    "        \n",
    "        return cv2.merge([B, G, R])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A patch preprocessor used to randomly extract M Ã— N pixel regions from an image during\n",
    "# training.\n",
    "class PatchPreprocessor:\n",
    "    def __init__(self, width, height):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        \n",
    "    def preprocess(self, image):\n",
    "        return extract_patches_2d(image, (self.height, self.width),\n",
    "                                 max_patches=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An over-sampling pre-processor used at testing time to sample five regions of an input image\n",
    "# (the four corners + center area) along with their corresponding horizontal flips\n",
    "class CropPreprocessor:\n",
    "    def __init__(self, width, height, horiz=True, inter=cv2.INTER_AREA):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.horiz = horiz\n",
    "        self.inter = inter\n",
    "    \n",
    "    def preprocess(self, image):\n",
    "        crops = []\n",
    "        \n",
    "        (h,w) = image.shape[:2]\n",
    "        coords = [\n",
    "            [0,0,self.width, self.height],\n",
    "            [w - self.width, 0, w, self.height],\n",
    "            [w - self.width, h - self.height, w, h],\n",
    "            [0, h-self.height, self.width, h]\n",
    "        ]\n",
    "        \n",
    "        dW = int(0.5*(w-self.width))\n",
    "        dH = int(0.5*(h-self.height))\n",
    "        coords.append([dW, dH, w-dW, h-dH])\n",
    "        \n",
    "        for (startX, startY, endX, endY) in coords:\n",
    "            crop = image[startY:endY, startX:endX]\n",
    "            crop = cv2.resize(crop, (self.width, self.height),\n",
    "                             interpolation=self.inter)\n",
    "            crop.append(crop)\n",
    "        \n",
    "        if self.horiz:\n",
    "            mirrors = [cv2.flip(c, 1) for c in crops]\n",
    "            crops.extend(mirrrors)\n",
    "        \n",
    "        return np.array(crops)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPV7yYvPjCp8xZZIye5Oay5",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "preprocessors.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
